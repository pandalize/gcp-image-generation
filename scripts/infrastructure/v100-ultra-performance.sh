#!/bin/bash
echo "ğŸš€ V100 ã‚¦ãƒ«ãƒˆãƒ©æ€§èƒ½ãƒ¢ãƒ¼ãƒ‰"
echo "=========================="

echo "ğŸ›‘ ç¾åœ¨ã®ãƒ—ãƒ­ã‚»ã‚¹åœæ­¢"
pkill -f "python main.py"
sleep 3

echo "âš¡ æœ€é«˜æ€§èƒ½è¨­å®š"
cd ~/ComfyUI
source comfyui_env/bin/activate

# GPUæœ€é©åŒ–ç’°å¢ƒå¤‰æ•°ï¼ˆã‚ˆã‚Šæ”»æ’ƒçš„ï¼‰
export PYTORCH_CUDA_ALLOC_CONF=max_split_size_mb:2048
export CUDA_VISIBLE_DEVICES=0
export CUDA_LAUNCH_BLOCKING=0
export TORCH_CUDNN_V8_API_ENABLED=1
export CUDA_CACHE_MAXSIZE=2147483647

echo "ğŸ”§ GPUå‘¨æ³¢æ•°æœ€å¤§åŒ–"
sudo nvidia-smi -pm 1
sudo nvidia-smi -ac 877,1530  # V100æœ€å¤§ã‚¯ãƒ­ãƒƒã‚¯è¨­å®š

echo "ğŸ’¾ ã‚·ã‚¹ãƒ†ãƒ æœ€é©åŒ–"
# CPUã‚¬ãƒãƒŠãƒ¼è¨­å®š
echo performance | sudo tee /sys/devices/system/cpu/cpu*/cpufreq/scaling_governor

# ãƒ‡ã‚£ã‚¹ã‚¯I/Oæœ€é©åŒ–
echo mq-deadline | sudo tee /sys/block/sda/queue/scheduler

# ãƒ¡ãƒ¢ãƒªæœ€é©åŒ–
echo 1 | sudo tee /proc/sys/vm/drop_caches
echo 10 | sudo tee /proc/sys/vm/swappiness

echo "ğŸš€ ComfyUIè¶…é«˜æ€§èƒ½èµ·å‹•"
nohup python main.py --listen 0.0.0.0 --port 8188 \
  --highvram \
  --fast \
  --dont-print-server \
  --preview-method none \
  > ~/comfyui_ultra.log 2>&1 &

echo "â³ èµ·å‹•å¾…æ©Ÿ"
sleep 15

echo "ğŸ“Š æœ€çµ‚ç¢ºèª"
nvidia-smi
curl -s http://localhost:8188/system_stats | head -20

echo ""
echo "ğŸ”¥ V100ã‚¦ãƒ«ãƒˆãƒ©æ€§èƒ½ãƒ¢ãƒ¼ãƒ‰å®Œäº†!"
echo "èµ·å‹•: http://34.70.230.62:8188"