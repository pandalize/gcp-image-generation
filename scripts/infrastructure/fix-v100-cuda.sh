#!/bin/bash
echo "ğŸ”§ V100 CUDAç’°å¢ƒä¿®å¾©ã‚¹ã‚¯ãƒªãƒ—ãƒˆ"
echo "=================================="

echo "ğŸ“‹ ç¾åœ¨ã®çŠ¶æ³ç¢ºèª"
nvidia-smi
echo ""

echo "ğŸ”„ CUDAã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒªã‚»ãƒƒãƒˆ"
sudo nvidia-smi -r || echo "GPUãƒªã‚»ãƒƒãƒˆå®Œäº†"

echo "ğŸ§¹ å¤ã„PyTorchã‚¢ãƒ³ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«"
cd ~/ComfyUI
source comfyui_env/bin/activate
pip uninstall -y torch torchvision torchaudio

echo "ğŸ”§ CUDA 11.8å¯¾å¿œPyTorchã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ï¼ˆV100äº’æ›ï¼‰"
pip install torch==2.0.1+cu118 torchvision==0.15.2+cu118 torchaudio==2.0.2+cu118 --index-url https://download.pytorch.org/whl/cu118

echo "ğŸ¯ CUDAç’°å¢ƒå¤‰æ•°è¨­å®š"
export CUDA_VISIBLE_DEVICES=0
export LD_LIBRARY_PATH=/usr/lib/x86_64-linux-gnu/nvidia/current:$LD_LIBRARY_PATH

echo "âœ… GPUèªè­˜ãƒ†ã‚¹ãƒˆ"
python -c "
import torch
print('PyTorch version:', torch.__version__)
print('CUDA available:', torch.cuda.is_available())
print('CUDA version:', torch.version.cuda if hasattr(torch.version, 'cuda') else 'None')
if torch.cuda.is_available():
    print('Device count:', torch.cuda.device_count())
    print('Device name:', torch.cuda.get_device_name(0))
    print('GPU Memory:', torch.cuda.get_device_properties(0).total_memory // 1024**3, 'GB')
    print('CUDA Capability:', torch.cuda.get_device_capability(0))
"

echo "ğŸš€ ComfyUI GPUãƒ¢ãƒ¼ãƒ‰èµ·å‹•"
nohup python main.py --listen 0.0.0.0 --port 8188 > ~/comfyui_gpu_fixed.log 2>&1 &

echo "â³ èµ·å‹•å¾…æ©Ÿ"
sleep 10

echo "ğŸ” èµ·å‹•çŠ¶æ³ç¢ºèª"
curl -s http://localhost:8188/system_stats | head -10 || echo "èµ·å‹•ä¸­..."

echo "ğŸ“‹ æœ€çµ‚ç¢ºèª"
echo "ComfyUIãƒ­ã‚°:"
tail -10 ~/comfyui_gpu_fixed.log

echo ""
echo "ğŸ‰ ä¿®å¾©å®Œäº†ï¼"
echo "ComfyUI GPUèµ·å‹•: http://34.70.230.62:8188"